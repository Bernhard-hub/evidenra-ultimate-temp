// UltimateReportService.ts - Complete data-driven scientific report generation
import APIService from '../../services/APIService';
import { ScientificArticleService } from './ScientificArticleService';
import { EvidenraBasisReportService } from './EvidenraBasisReportService';
import { ScientificRigorityService, ScientificRigorityData } from './ScientificRigorityService';

export interface ProjectData {
  name: string;
  documents: DocumentData[];
  categories: CategoryData[];
  codings: CodingData[];
  patterns?: any[];
  questions?: any[];
  metadata?: {
    researcher?: string;
    institution?: string;
  };
}

export interface DocumentData {
  id: string;
  name: string;
  content: string;
  wordCount: number;
}

export interface CategoryData {
  name: string;
  description?: string;
  color?: string;
}

export interface CodingData {
  id: string;
  text: string;
  category: string;
  document: string;
  position?: number;
}

export interface UltimateAnalysisData {
  projectOverview: {
    name: string;
    totalDocuments: number;
    totalWords: number;
    totalCodings: number;
    totalCategories: number;
    researchDomain: string;
  };

  basisData: {
    documentSummaries: DocumentSummary[];
    basicStatistics: BasicStatistics;
  };

  enhancedData: {
    akihScore: any;
    categoryAnalysis: CategoryAnalysis[];
    emergentPatterns: string[];
    crossCategoryConnections: string[];
    qualityMetrics: QualityMetrics;
  };

  literatureMapping: {
    documents: DocumentWithCitations[];
    extractedAuthors: AuthorExtraction[];
    citationDatabase: Citation[];
  };

  researchInsights: {
    keyFindings: string[];
    theoreticalContributions: string[];
    practicalImplications: string[];
    futureResearch: string[];
  };

  // üî¨ NEW: Scientific Rigority & Reflexivity Integration
  scientificRigority?: ScientificRigorityData;
}

interface DocumentSummary {
  name: string;
  wordCount: number;
  keyTopics: string[];
  methodology: string;
  findings: string;
  extractedQuotes: string[];
}

interface BasicStatistics {
  averageDocumentLength: number;
  categoryDistribution: { [category: string]: number };
  codingDensity: number;
}

interface CategoryAnalysis {
  name: string;
  codingCount: number;
  significance: string;
  representativeQuotes: string[];
  connectionStrength: number;
}

interface QualityMetrics {
  precision: number;
  recall: number;
  f1Score: number;
  accuracy: number;
  interRaterReliability?: number;
}

interface DocumentWithCitations {
  name: string;
  content: string;
  extractedAuthor: string;
  year: number;
  pageCount: number;
  citablePassages: CitablePassage[];
}

interface AuthorExtraction {
  documentName: string;
  extractedAuthor: string;
  year: number;
  confidence: number;
}

interface Citation {
  author: string;
  year: number;
  title: string;
  pages: string;
  quote: string;
  context: string;
}

interface CitablePassage {
  text: string;
  page: number;
  context: string;
  category: string;
}

export class UltimateReportService {

  /**
   * Generate ULTIMATE Report by aggregating BASIS + ENHANCED data with real citations
   */
  static async generateUltimateReport(
    project: ProjectData,
    apiSettings: { provider: string; model: string; apiKey: string },
    language: string = 'de',
    reportType: string = 'ENHANCED',
    userSettings?: any,
    onStatusUpdate?: (status: string) => void
  ): Promise<{ success: boolean; content?: string; error?: string; wordCount?: number; cost?: number }> {

    try {
      // Step 1: Aggregate all data (BASIS + ENHANCED)
      onStatusUpdate?.('üìä Aggregating BASIS + ENHANCED data...');
      const ultimateData = await this.aggregateAllData(project);

      // Step 2: Generate comprehensive scientific article in multiple sections for 8000+ words
      onStatusUpdate?.('üß† Generating comprehensive 8000+ word scientific article...');

      const sections = [
        { name: 'Abstract & Introduction', words: 1200, priority: 1 },
        { name: 'Literature Review', words: 2000, priority: 2 },
        { name: 'Methodology', words: 800, priority: 3 },
        { name: 'Results & Analysis', words: 2500, priority: 4 },
        { name: 'Discussion & Conclusion', words: 1500, priority: 5 }
      ];

      let fullArticle = '';
      let totalWordCount = 0;
      let totalCost = 0;

      for (let i = 0; i < sections.length; i++) {
        const section = sections[i];
        onStatusUpdate?.(`üìù Writing ${section.name} (${section.words} words target)...`);

        const sectionResult = await this.generateArticleSection(
          section, ultimateData, apiSettings, language, i, sections.length, onStatusUpdate
        );

        if (sectionResult.success) {
          fullArticle += sectionResult.content + '\n\n---\n\n';
          totalWordCount += sectionResult.wordCount || 0;
          totalCost += sectionResult.cost || 0;

          onStatusUpdate?.(`‚úÖ ${section.name} completed (${sectionResult.wordCount} words)`);
        } else {
          return { success: false, error: `Failed to generate ${section.name}: ${sectionResult.error}` };
        }

        // Brief pause between sections to avoid rate limits
        await this.delay(2000);
      }

      // Add final literature section
      onStatusUpdate?.('üìö Generating comprehensive literature references...');
      const referencesResult = await this.generateReferencesSection(ultimateData, apiSettings, language, onStatusUpdate);

      if (referencesResult.success) {
        fullArticle += referencesResult.content;
        totalWordCount += referencesResult.wordCount || 0;
        totalCost += referencesResult.cost || 0;
      }

      return {
        success: true,
        content: fullArticle,
        wordCount: totalWordCount,
        cost: totalCost
      };

    } catch (error: any) {
      return { success: false, error: error.message };
    }
  }

  /**
   * Step 1: Aggregate BASIS + ENHANCED data
   * üî¨ Enhanced: Now includes Scientific Rigority & Reflexivity data
   */
  private static async aggregateAllData(project: ProjectData): Promise<UltimateAnalysisData> {

    // BASIS Data Collection
    const basisData = await this.collectBasisData(project);

    // ENHANCED Data Collection
    const enhancedData = await this.collectEnhancedData(project);

    // Literature Mapping
    const literatureMapping = await this.createLiteratureMapping(project);

    // Research Insights Extraction
    const researchInsights = await this.extractResearchInsights(project, basisData, enhancedData);

    // üî¨ NEW: Extract Scientific Rigority & Reflexivity Data
    const scientificRigority = ScientificRigorityService.extractRigorityData(project);
    console.log('üî¨ Scientific Rigority Data extracted:', {
      memos: scientificRigority.summary.totalMemos,
      notes: scientificRigority.summary.totalNotes,
      reflexivity: scientificRigority.summary.totalReflexivityEntries,
      score: scientificRigority.scores.totalScore.toFixed(1)
    });

    return {
      projectOverview: {
        name: project.name,
        totalDocuments: project.documents.length,
        totalWords: project.documents.reduce((sum, d) => sum + (d.wordCount || 0), 0),
        totalCodings: project.codings.length,
        totalCategories: project.categories.length,
        researchDomain: this.determineResearchDomain(project.name, project.documents)
      },
      basisData,
      enhancedData,
      literatureMapping,
      researchInsights,
      scientificRigority // üî¨ Include rigority data in analysis
    };
  }

  /**
   * Collect BASIS data
   */
  private static async collectBasisData(project: ProjectData) {
    const documentSummaries: DocumentSummary[] = project.documents.map(doc => ({
      name: doc.name,
      wordCount: doc.wordCount,
      keyTopics: this.extractKeyTopics(doc.content),
      methodology: this.extractMethodology(doc.content),
      findings: this.extractFindings(doc.content),
      extractedQuotes: this.extractSignificantQuotes(doc.content, project.codings)
    }));

    const basicStatistics: BasicStatistics = {
      averageDocumentLength: project.documents.reduce((sum, d) => sum + d.wordCount, 0) / project.documents.length,
      categoryDistribution: this.calculateCategoryDistribution(project.codings),
      codingDensity: project.codings.length / project.documents.reduce((sum, d) => sum + d.wordCount, 0) * 1000
    };

    return {
      documentSummaries,
      basicStatistics
    };
  }

  /**
   * Collect ENHANCED data
   */
  private static async collectEnhancedData(project: ProjectData) {
    // Use existing ENHANCED logic from ScientificArticleService
    const akihScore = await ScientificArticleService.calculateAKIHScore(project);

    const categoryAnalysis: CategoryAnalysis[] = project.categories.map(cat => {
      const categoryCodings = project.codings.filter(c => c.category === cat.name);
      return {
        name: cat.name,
        codingCount: categoryCodings.length,
        significance: this.calculateCategorySignificance(project.codings, cat.name),
        representativeQuotes: categoryCodings.slice(0, 5).map(c => c.text),
        connectionStrength: this.calculateConnectionStrength(cat.name, project.codings)
      };
    });

    return {
      akihScore,
      categoryAnalysis,
      emergentPatterns: this.identifyEmergentPatterns(project.codings),
      crossCategoryConnections: this.findCrossCategoryConnections(project.codings, project.categories),
      qualityMetrics: {
        precision: 0.85,
        recall: 0.78,
        f1Score: 0.81,
        accuracy: 0.83
      }
    };
  }

  /**
   * Create literature mapping with real citations
   */
  private static async createLiteratureMapping(project: ProjectData) {
    const documents: DocumentWithCitations[] = project.documents.map((doc, index) => {
      const authorExtraction = this.extractAuthorInfo(doc.content, index);
      const citablePassages = this.extractCitablePassages(doc, project.codings);

      return {
        name: doc.name,
        content: doc.content,
        extractedAuthor: authorExtraction.author,
        year: authorExtraction.year,
        pageCount: Math.ceil(doc.wordCount / 250),
        citablePassages
      };
    });

    const extractedAuthors: AuthorExtraction[] = documents.map(doc => ({
      documentName: doc.name,
      extractedAuthor: doc.extractedAuthor,
      year: doc.year,
      confidence: 0.8
    }));

    const citationDatabase: Citation[] = documents.flatMap(doc =>
      doc.citablePassages.map(passage => ({
        author: doc.extractedAuthor,
        year: doc.year,
        title: doc.name,
        pages: `S. ${passage.page}`,
        quote: passage.text,
        context: passage.context
      }))
    );

    return {
      documents,
      extractedAuthors,
      citationDatabase
    };
  }

  /**
   * Extract research insights
   */
  private static async extractResearchInsights(project: ProjectData, basisData: any, enhancedData: any) {
    // Extract key findings from codings and documents
    const keyFindings = project.codings
      .filter(coding => coding.text.length > 50)
      .slice(0, 10)
      .map(coding => coding.text);

    const theoreticalContributions = enhancedData.categoryAnalysis
      .filter(cat => cat.significance === 'Hoch')
      .map(cat => `${cat.name}: ${cat.representativeQuotes[0]?.substring(0, 200)}...`);

    const practicalImplications = project.documents
      .flatMap(doc => this.extractPracticalImplications(doc.content))
      .slice(0, 5);

    const futureResearch = [
      'Longitudinal studies to validate findings',
      'Cross-cultural validation of patterns',
      'Implementation research for practical applications',
      'Mixed-methods validation studies',
      'Technology-enhanced intervention studies'
    ];

    return {
      keyFindings,
      theoreticalContributions,
      practicalImplications,
      futureResearch
    };
  }

  /**
   * Generate data-driven scientific article with rate limit handling
   */
  private static async generateDataDrivenArticle(
    ultimateData: UltimateAnalysisData,
    apiSettings: { provider: string; model: string; apiKey: string },
    language: string,
    onStatusUpdate?: (status: string) => void
  ): Promise<{ success: boolean; content?: string; error?: string; wordCount?: number; cost?: number }> {

    // Smart data compression to avoid rate limits
    const compressedDataContext = this.createCompressedDataContext(ultimateData);

    const messages = [
      {
        role: 'system',
        content: language === 'de'
          ? `Du bist ein preisgekr√∂nter Wissenschaftsautor mit internationaler Anerkennung, der einen UMFASSENDEN, datenreichen Forschungsartikel mit au√üergew√∂hnlicher Literaturintegration schreibt.

üö® **ABSOLUTE L√ÑNGEN-ANFORDERUNGEN (MINDESTENS 8000-12000 W√ñRTER):**
- NIEMALS unter 8000 W√∂rter schreiben
- JEDER Abschnitt muss VOLLST√ÑNDIG ausformuliert werden
- KEINE K√ºrzungen oder Zusammenfassungen
- VOLLST√ÑNDIGER wissenschaftlicher Artikel in EINER Antwort

üö´ **ABSOLUT VERBOTEN - NIEMALS:**
- KEINE R√ºckfragen stellen ("Soll ich...?", "M√∂chten Sie...?", "Ben√∂tigst du...?")
- KEINE Nachfragen nach Originaldokumenten - ALLE DATEN sind bereits im Kontext bereitgestellt
- NICHT auf weitere Instruktionen warten - SOFORT den vollst√§ndigen Artikel schreiben
- NICHT fragen ob mit Kapitel 1 begonnen werden soll - EINFACH BEGINNEN
- NICHT nach Validierungschecklisten fragen - Die Daten sind VOLLST√ÑNDIG

üéØ **LITERATUR-SCHWERPUNKT ANFORDERUNGEN:**
- MINDESTENS 25-35 verschiedene Literaturverweise aus den bereitgestellten Prim√§rquellen
- Jeder Abschnitt muss 5-8 unterschiedliche Quellen integrieren
- Konkrete APA-Zitationen: (Autor, Jahr: S. XX)
- Direkte Zitate zur Untermauerung jeder Hauptaussage
- Vollst√§ndiges Literaturverzeichnis mit ALLEN verwendeten Quellen

üìä **STRUKTUR mit LITERATUR-FOKUS (MINDESTENS 8000-12000 W√∂rter):**
1. **Abstract (600-800 W√∂rter)** + 4-6 Schl√ºsselreferenzen
2. **Einleitung (1200-1500 W√∂rter)** + 8-12 Literaturverweise mit ausf√ºhrlicher Kontextualisierung
3. **Literatur√ºbersicht (2000-2500 W√∂rter)** + 15-20 Quellenbez√ºge mit detaillierter Analyse
4. **Methodik (800-1200 W√∂rter)** + 5-8 methodische Referenzen mit vollst√§ndiger Begr√ºndung
5. **Ergebnisse (2500-3500 W√∂rter)** + 12-18 Datenbelege mit ausf√ºhrlichen Zitaten und Interpretationen
6. **Diskussion (1500-2000 W√∂rter)** + 8-12 vergleichende Referenzen mit theoretischer Einbettung
7. **Fazit (600-1000 W√∂rter)** + 4-6 Schlussfolgerungsreferenzen mit Zukunftsperspektiven
8. **Vollst√§ndiges Literaturverzeichnis** mit allen 25-35+ Quellen in perfektem APA-Format

üí° **CONTENT-EXPANSION-STRATEGIEN F√úR MAXIMALE WORTANZAHL:**
- **Detaillierte Kategorienbeschreibung**: Jede Kategorie min. 300-500 W√∂rter mit vollst√§ndigen Beispielen
- **Vollst√§ndige Originalzitate**: Mindestens 15-20 l√§ngere Zitate (je 50-100 W√∂rter) aus Prim√§rquellen
- **Systematische Dokumentenanalyse**: Jedes Dokument individual besprochen mit spezifischen Erkenntnissen
- **Theoretische Kontextualisierung**: Umfassende Einbettung in bestehende Theorien und Frameworks
- **Methodologische Ausf√ºhrlichkeit**: Detaillierte Begr√ºndung jeder methodischen Entscheidung
- **Ergebnisinterpretation**: Ausf√ºhrliche Interpretation jedes Ergebnisses mit multiplen Perspektiven
- **Praktische Implikationen**: Vollst√§ndige Ausarbeitung aller praktischen Anwendungen
- **Zukunftsforschung**: Detaillierte Darstellung von Forschungsl√ºcken und zuk√ºnftigen Studien

üö® **ABSOLUT KRITISCH F√úR L√ÑNGE:**
- Bei 98 verf√ºgbaren Dokumenten sind weniger als 25 Zitate INAKZEPTABEL
- JEDE Hauptaussage braucht ausf√ºhrlichen Quellenbeleg mit Kontext
- JEDER Abschnitt muss die Mindestl√§nge erreichen oder √ºberschreiten
- Literaturverzeichnis muss ALLE verwendeten Quellen enthalten
- VOLLST√ÑNDIGER 8000-12000 W√∂rter Artikel in EINER Antwort OHNE Unterbrechung`

          : `You are a data analyst writing a PURE DATA ANALYSIS REPORT using EVIDENRA methodology. Focus EXCLUSIVELY on empirical findings.

üéØ **PURE DATA ANALYSIS FOCUS:**
- ONLY analyze provided project data
- NO theoretical speculation
- Direct document quotes and citations
- Empirical findings and patterns
- EVIDENRA qualitative analysis methodology

üìä **DATA ANALYSIS STRUCTURE (3000-4000 words):**
1. Executive Summary (300 words)
2. EVIDENRA Methodology Overview (400 words)
3. Document Corpus Analysis (800 words)
4. Category and Coding Results (1000 words) - PURE DATA
5. Pattern Recognition Findings (600 words)
6. Empirical Conclusions (400 words)
7. Data References

üö® **CRITICAL DATA REQUIREMENT:**
YOU MUST USE THE EXACT CODING COUNTS provided in the data context. For each category, use the ACTUAL number of codings shown in the "(X Codierungen)" format in the KERNKATEGORIEN section. DO NOT write "0" codings - use the real numbers from the provided data.

‚ö†Ô∏è **CRITICAL:** Write complete analysis in ONE response. NO "[Fortsetzung folgt]", NO "aufgrund der Zeichenbegrenzung", NO incomplete endings. MUST be fully finished.

üö´ **ABSOLUT VERBOTEN - NIEMALS:**
- KEINE R√ºckfragen stellen ("Soll ich...?", "M√∂chten Sie...?", "Ben√∂tigst du...?")
- KEINE Nachfragen nach Originaldokumenten - ALLE DATEN sind bereits im Kontext bereitgestellt
- KEINE Unterbrechungen oder Pausen im Schreibprozess
- NICHT auf weitere Instruktionen warten - SOFORT den vollst√§ndigen Artikel schreiben
- NICHT fragen ob mit Kapitel 1 begonnen werden soll - EINFACH BEGINNEN

‚úÖ **STATTDESSEN:** Die bereitgestellten Daten sind VOLLST√ÑNDIG und AUSREICHEND. Beginne SOFORT mit dem Schreiben des kompletten Artikels ohne jede Nachfrage.`
      },
      {
        role: 'user',
        content: `# ULTIMATE DATENGETRIEBENER FORSCHUNGSARTIKEL mit UMFANGREICHER LITERATUR

${compressedDataContext}

## üö® KRITISCHE LITERATUR-ANFORDERUNGEN:
Bei **${ultimateData.projectOverview.totalDocuments} verf√ºgbaren Dokumenten** sind mindestens **15-20 verschiedene Literaturverweise** ZWINGEND erforderlich!

**ABSOLUT INAKZEPTABEL:**
- Nur 3 Literaturverweise bei 98 Dokumenten
- Oberfl√§chliche Quellenintegration
- Unvollst√§ndiges Literaturverzeichnis

**ZWINGEND ERFORDERLICH:**
- Jeder Absatz braucht 2-3 Quellenverweise
- Direkte Zitate aus den bereitgestellten Dokumenten
- Vollst√§ndige APA-Zitationen (Autor, Jahr: S. XX)
- Literaturverzeichnis mit allen 15-20+ verwendeten Quellen

## üö® KRITISCHE DATENANFORDERUNG F√úR KATEGORIE-ANALYSE:
Du MUSST die EXAKTEN Kodierungsanzahlen aus den KERNKATEGORIEN verwenden. JEDE Kategorie hat eine spezifische Anzahl Kodierungen in Klammern angegeben - verwende diese echten Zahlen, NIEMALS "0"!

Beispiel aus den Daten:
- **[1] Digitale Medienkompetenz** (15 Codierungen, Signifikanz: Hoch)
- **[2] Technologische Sozialisation** (23 Codierungen, Signifikanz: Sehr Hoch)

Verwende DIESE echten Zahlen f√ºr jede Kategorie!

## FINALE ANWEISUNG:
Schreibe JETZT einen vollst√§ndigen wissenschaftlichen Artikel mit UMFANGREICHER LITERATURINTEGRATION basierend auf den obigen REALEN DATEN. Verwende die bereitgestellten Autoren, Jahre und Textstellen f√ºr konkrete Zitationen. MINDESTENS 15-20 verschiedene Literaturverweise sind PFLICHT!`
      }
    ];

    // Implement intelligent server overload handling with enhanced retry logic
    return this.callAPIWithRetry(apiSettings, messages, 8192, 5, onStatusUpdate);
  }

  /**
   * API call with intelligent server overload handling for 529 errors
   */
  private static async callAPIWithRetry(
    apiSettings: { provider: string; model: string; apiKey: string },
    messages: any[],
    maxTokens: number,
    maxRetries: number = 5,
    onStatusUpdate?: (status: string) => void
  ): Promise<{ success: boolean; content?: string; error?: string; wordCount?: number; cost?: number }> {

    let consecutiveOverloads = 0;

    for (let attempt = 0; attempt < maxRetries; attempt++) {
      try {
        const result = await APIService.callAPI(
          apiSettings.provider,
          apiSettings.model,
          apiSettings.apiKey,
          messages,
          maxTokens
        );

        if (result.success) {
          // Reset overload counter on success
          consecutiveOverloads = 0;
          return {
            success: true,
            content: result.content,
            wordCount: result.content.split(' ').length,
            cost: (result.content.split(' ').length / 1000) * 0.002
          };
        } else if (this.isServerOverloadError(result.error)) {
          consecutiveOverloads++;
          const overloadStrategy = this.getOverloadStrategy(attempt, consecutiveOverloads);

          console.log(`üîÑ Anthropic server overload detected (529). ${overloadStrategy.message}`);
          onStatusUpdate?.(`üîÑ Server overload detected. ${overloadStrategy.message}`);

          if (attempt < maxRetries - 1) {
            // Implement graceful degradation after multiple overloads
            if (consecutiveOverloads >= 3 && maxTokens > 5000) {
              maxTokens = Math.floor(maxTokens * 0.7); // Reduce token count by 30%
              console.log(`üéØ Reducing token limit to ${maxTokens} to ease server load`);
              onStatusUpdate?.(`üéØ Reducing request size to ease server load...`);
            }

            await this.delay(overloadStrategy.waitTime);
            continue;
          } else {
            return this.createGracefulFailureResponse(consecutiveOverloads);
          }
        } else if (result.error && result.error.includes('rate')) {
          // Standard rate limit handling
          const waitTime = Math.pow(2, attempt) * 2000; // 2s, 4s, 8s, 16s, 32s
          console.log(`‚è±Ô∏è Rate limit detected. Waiting ${waitTime}ms before retry ${attempt + 1}/${maxRetries}`);
          await this.delay(waitTime);
          continue;
        } else {
          return { success: false, error: result.error };
        }
      } catch (error: any) {
        const errorMessage = error.message || error.toString();

        if (this.isServerOverloadError(errorMessage)) {
          consecutiveOverloads++;
          const overloadStrategy = this.getOverloadStrategy(attempt, consecutiveOverloads);

          console.log(`üîÑ Server overload exception caught. ${overloadStrategy.message}`);

          if (attempt < maxRetries - 1) {
            await this.delay(overloadStrategy.waitTime);
            continue;
          } else {
            return this.createGracefulFailureResponse(consecutiveOverloads);
          }
        } else if (errorMessage.includes('rate') && attempt < maxRetries - 1) {
          const waitTime = Math.pow(2, attempt) * 2000;
          console.log(`‚è±Ô∏è Rate limit exception. Waiting ${waitTime}ms before retry ${attempt + 1}/${maxRetries}`);
          await this.delay(waitTime);
          continue;
        } else {
          return { success: false, error: errorMessage };
        }
      }
    }

    return { success: false, error: 'Max retries exceeded. Server may be experiencing high load.' };
  }

  /**
   * Detect server overload errors (529, overloaded, capacity)
   */
  private static isServerOverloadError(error: string | undefined): boolean {
    if (!error) return false;
    const errorLower = error.toLowerCase();
    return errorLower.includes('529') ||
           errorLower.includes('overloaded') ||
           errorLower.includes('capacity') ||
           errorLower.includes('server is overloaded') ||
           errorLower.includes('too many requests');
  }

  /**
   * Get intelligent backoff strategy for server overloads
   */
  private static getOverloadStrategy(attempt: number, consecutiveOverloads: number): { waitTime: number; message: string } {
    // Progressive backoff: starts at 30s, increases exponentially with consecutive overloads
    const baseWait = 30000; // 30 seconds base wait for overloads
    const multiplier = Math.pow(1.5, consecutiveOverloads - 1); // 1x, 1.5x, 2.25x, 3.375x...
    const waitTime = Math.min(baseWait * multiplier, 300000); // Cap at 5 minutes

    const minutes = Math.floor(waitTime / 60000);
    const seconds = Math.floor((waitTime % 60000) / 1000);

    let message = `Attempt ${attempt + 1}/5. `;

    if (consecutiveOverloads === 1) {
      message += `First overload - waiting ${minutes}m ${seconds}s`;
    } else if (consecutiveOverloads <= 3) {
      message += `${consecutiveOverloads} consecutive overloads - extended wait of ${minutes}m ${seconds}s`;
    } else {
      message += `High server load detected (${consecutiveOverloads} overloads) - waiting ${minutes}m ${seconds}s`;
    }

    return { waitTime, message };
  }

  /**
   * Create graceful failure response with helpful information
   */
  private static createGracefulFailureResponse(consecutiveOverloads: number): { success: boolean; error: string } {
    let errorMessage = 'üö® ULTIMATE Report generation temporarily unavailable due to high server demand.\n\n';

    if (consecutiveOverloads >= 5) {
      errorMessage += '‚ö° The Anthropic Claude API is experiencing extremely high load.\n';
      errorMessage += 'üí° Recommendations:\n';
      errorMessage += '‚Ä¢ Try again in 10-15 minutes when server load decreases\n';
      errorMessage += '‚Ä¢ Consider using BASIS or ENHANCED mode as alternatives\n';
      errorMessage += '‚Ä¢ Peak usage times may require patience\n\n';
    } else {
      errorMessage += 'üìä Multiple server overload responses received.\n';
      errorMessage += 'üí° The service is temporarily overwhelmed but should recover shortly.\n';
      errorMessage += '‚è∞ Please try again in 5-10 minutes.\n\n';
    }

    errorMessage += 'üîÑ Your optimized ULTIMATE settings are preserved and ready for retry.';

    return { success: false, error: errorMessage };
  }

  /**
   * Generate individual article section with focused prompts
   */
  private static async generateArticleSection(
    section: { name: string; words: number; priority: number },
    ultimateData: UltimateAnalysisData,
    apiSettings: { provider: string; model: string; apiKey: string },
    language: string,
    sectionIndex: number,
    totalSections: number,
    onStatusUpdate?: (status: string) => void
  ): Promise<{ success: boolean; content?: string; error?: string; wordCount?: number; cost?: number }> {

    const compressedDataContext = this.createCompressedDataContext(ultimateData);

    const sectionMessages = [
      {
        role: 'system',
        content: language === 'de'
          ? `Du bist ein Experte f√ºr wissenschaftliches Schreiben und erstellst Abschnitt ${sectionIndex + 1} von ${totalSections} eines umfassenden Forschungsartikels.

üéØ **SECTION-SPEZIFISCHE ANFORDERUNGEN f√ºr "${section.name}":**
- Zielwortanzahl: MINDESTENS ${section.words} W√∂rter
- Fokus: ${this.getSectionFocus(section.name)}
- Literaturintegration: ${this.getSectionLiteratureRequirements(section.name)}
- Stil: Wissenschaftlich, publikationsreif, detailliert

üö® **KRITISCHE L√ÑNGEN-ANFORDERUNG:**
- NIEMALS unter ${Math.floor(section.words * 0.8)} W√∂rter schreiben
- Ideal: ${section.words}-${Math.floor(section.words * 1.2)} W√∂rter
- VOLLST√ÑNDIGE Ausformulierung ohne K√ºrzungen

üí° **CONTENT-EXPANSION f√ºr ${section.name}:**
${this.getSectionExpansionStrategy(section.name)}

üìö **LITERATUR-INTEGRATION:**
- Mindestens ${Math.ceil(section.words / 200)} verschiedene Quellenverweise
- Direkte Zitate zur Unterst√ºtzung aller Hauptargumente
- APA-Format: (Autor, Jahr: S. XX)`

          : `You are writing section ${sectionIndex + 1} of ${totalSections} of a comprehensive research article.

üéØ **SECTION REQUIREMENTS for "${section.name}":**
- Target: MINIMUM ${section.words} words
- Focus: ${this.getSectionFocus(section.name)}
- Literature: ${this.getSectionLiteratureRequirements(section.name)}

üö® **CRITICAL LENGTH REQUIREMENT:**
- NEVER write less than ${Math.floor(section.words * 0.8)} words
- Target: ${section.words}-${Math.floor(section.words * 1.2)} words`
      },
      {
        role: 'user',
        content: `# ${section.name.toUpperCase()} SECTION (${section.words} W√ñRTER ZIEL)

${compressedDataContext}

## SECTION-SPEZIFISCHE ANWEISUNG:
Schreibe JETZT den vollst√§ndigen "${section.name}" Abschnitt mit MINDESTENS ${section.words} W√∂rtern.

${this.getSectionSpecificPrompt(section.name, ultimateData)}

**ABSOLUT KRITISCH:**
- Vollst√§ndige ${section.words} W√∂rter ohne K√ºrzungen
- Umfassende Literaturintegration aus den Prim√§rquellen
- Wissenschaftlicher Publikationsstandard
- KEINE "[Fortsetzung folgt]" oder Unterbrechungen`
      }
    ];

    return this.callAPIWithRetry(apiSettings, sectionMessages, 8192, 5, onStatusUpdate);
  }

  /**
   * Generate comprehensive references section
   */
  private static async generateReferencesSection(
    ultimateData: UltimateAnalysisData,
    apiSettings: { provider: string; model: string; apiKey: string },
    language: string,
    onStatusUpdate?: (status: string) => void
  ): Promise<{ success: boolean; content?: string; error?: string; wordCount?: number; cost?: number }> {

    const referencesMessages = [
      {
        role: 'system',
        content: language === 'de'
          ? `Du erstellst das vollst√§ndige Literaturverzeichnis f√ºr den wissenschaftlichen Artikel.

üéØ **LITERATURVERZEICHNIS-ANFORDERUNGEN:**
- Vollst√§ndige APA-Formatierung
- Alphabetische Sortierung nach Autorennamen
- Mindestens 25-30 Eintr√§ge aus den Prim√§rquellen
- Konsistente Formatierung
- Realistische Seitenzahlen basierend auf Dokumentl√§nge`

          : `Create the complete references section in APA format with 25-30 entries from primary sources.`
      },
      {
        role: 'user',
        content: `# VOLLST√ÑNDIGES LITERATURVERZEICHNIS

## VERF√úGBARE PRIM√ÑRQUELLEN:
${ultimateData.literatureMapping.documents.map((doc, i) => `
${i + 1}. ${doc.extractedAuthor} (${doc.year}): "${doc.name}"
   - Seitenzahl: ${doc.pageCount} Seiten
   - Zitierf√§hige Passagen: ${doc.citablePassages.length}
   - Hauptthemen: ${doc.citablePassages.map(p => p.category).slice(0, 3).join(', ')}
`).join('')}

## ANWEISUNG:
Erstelle ein vollst√§ndiges APA-Literaturverzeichnis mit ALLEN verf√ºgbaren Quellen.
Verwende realistische Publikationsdetails basierend auf den Dokumentinhalten.

**FORMAT-BEISPIEL:**
M√ºller, H. (2023): Qualitative Forschungsmethoden in der Bildungsanalyse. *Zeitschrift f√ºr Bildungsforschung*, 45(3), 123-145.

Schmidt, K. & Weber, L. (2022): Datenanalyse in der empirischen Sozialforschung. *Empirische Studien*, 28(2), 67-89.`
      }
    ];

    return this.callAPIWithRetry(apiSettings, referencesMessages, 4096, 3, onStatusUpdate);
  }

  /**
   * Get section-specific focus
   */
  private static getSectionFocus(sectionName: string): string {
    if (sectionName.includes('Abstract') || sectionName.includes('Introduction')) {
      return 'Forschungsziel, Problemstellung, √úberblick und Struktur';
    } else if (sectionName.includes('Literature')) {
      return 'Umfassende Literaturanalyse, theoretische Grundlagen, Forschungsl√ºcken';
    } else if (sectionName.includes('Method')) {
      return 'Detaillierte Methodenbeschreibung, Begr√ºndung, Validit√§t';
    } else if (sectionName.includes('Results') || sectionName.includes('Analysis')) {
      return 'Ausf√ºhrliche Ergebnisdarstellung, Datenanalyse, Musteridentifikation';
    } else if (sectionName.includes('Discussion') || sectionName.includes('Conclusion')) {
      return 'Interpretation, Implikationen, Limitationen, Zukunftsperspektiven';
    }
    return 'Wissenschaftliche Analyse und Erkenntnisse';
  }

  /**
   * Get section-specific literature requirements
   */
  private static getSectionLiteratureRequirements(sectionName: string): string {
    if (sectionName.includes('Literature')) {
      return '15-20 Literaturverweise mit ausf√ºhrlicher Diskussion';
    } else if (sectionName.includes('Results') || sectionName.includes('Analysis')) {
      return '8-12 Datenbelege mit direkten Zitaten';
    } else if (sectionName.includes('Discussion')) {
      return '10-15 vergleichende Literaturverweise';
    }
    return '5-8 relevante Literaturverweise';
  }

  /**
   * Get section expansion strategy
   */
  private static getSectionExpansionStrategy(sectionName: string): string {
    if (sectionName.includes('Literature')) {
      return `- Jede Quelle ausf√ºhrlich diskutieren (150-200 W√∂rter pro Quelle)
- Theoretische Frameworks detailliert erl√§utern
- Kritische Analyse bestehender Forschung
- Identifikation von Forschungsl√ºcken`;
    } else if (sectionName.includes('Results')) {
      return `- Jede Kategorie detailliert beschreiben
- Umfangreiche Originalzitate einbinden
- Quantitative und qualitative Befunde
- Muster und Verbindungen ausf√ºhrlich analysieren`;
    }
    return '- Alle Aspekte vollst√§ndig ausformulieren\n- Detaillierte Beispiele und Belege\n- Umfassende Kontextualisierung';
  }

  /**
   * Get section-specific prompt
   */
  private static getSectionSpecificPrompt(sectionName: string, ultimateData: UltimateAnalysisData): string {
    if (sectionName.includes('Abstract') || sectionName.includes('Introduction')) {
      return `Schreibe Abstract (300 W√∂rter) und Einleitung (900 W√∂rter) mit:
- Klare Problemstellung und Forschungsfragen
- √úberblick √ºber die ${ultimateData.projectOverview.totalDocuments} Dokumente
- Strukturierung des gesamten Artikels
- Wissenschaftliche Relevanz und Beitrag`;
    } else if (sectionName.includes('Literature')) {
      return `Erstelle umfassende Literatur√ºbersicht (2000 W√∂rter) mit:
- Systematische Analyse aller ${ultimateData.projectOverview.totalDocuments} Prim√§rquellen
- Theoretische Einordnung und Frameworks
- Kritische Diskussion bestehender Erkenntnisse
- Identifikation von Forschungsl√ºcken`;
    }
    return `Erstelle vollst√§ndigen ${sectionName} Abschnitt mit allen erforderlichen Details und Literaturverweisen.`;
  }

  /**
   * Delay utility for retry mechanism
   */
  private static delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * Create optimized data context for AI (maximum literature integration)
   */
  private static createCompressedDataContext(data: UltimateAnalysisData): string {
    // Select top 8 documents and top 8 categories for better literature coverage
    const topDocuments = data.basisData.documentSummaries.slice(0, 8);
    const topCategories = data.enhancedData.categoryAnalysis
      .sort((a, b) => b.codingCount - a.codingCount)
      .slice(0, 8);

    return `## PROJEKT√úBERSICHT
**Titel:** ${data.projectOverview.name}
**Umfang:** ${data.projectOverview.totalDocuments} Dokumente (${data.projectOverview.totalWords.toLocaleString()} W√∂rter)
**Analytische Tiefe:** ${data.projectOverview.totalCodings} Codierungen, ${data.projectOverview.totalCategories} Kategorien

## PRIM√ÑRLITERATUR (Top 8 von ${data.projectOverview.totalDocuments})
${topDocuments.map((doc, i) => `
**[${i+1}] "${doc.name}"** (${doc.wordCount.toLocaleString()} W√∂rter)
Themen: ${doc.keyTopics.slice(0, 2).join(', ')}
Erkenntnisse: ${doc.findings}
Zentrales Zitat: "${doc.extractedQuotes[0] || 'Analyserelevanter Inhalt'}"
${doc.extractedQuotes.slice(1, 3).map(quote => `- "${quote}"`).join('\n')}`).join('\n')}

## KERNKATEGORIEN (Top 8 von ${data.projectOverview.totalCategories})
${topCategories.map((cat, i) => `
**[${i+1}] ${cat.name}** (${cat.codingCount} Codierungen, Signifikanz: ${cat.significance})
Schl√ºsselaussage: "${cat.representativeQuotes[0] || 'Kategorierelevant'}"
Zus√§tzliche Belege: ${cat.representativeQuotes.slice(1, 3).map(q => `"${q.substring(0, 80)}..."`).join('; ')}`).join('\n')}

## VOLLST√ÑNDIGE LITERATURLISTE f√ºr Zitationen
${data.literatureMapping.documents.map((doc, i) => `
**${doc.extractedAuthor} (${doc.year}):** "${doc.name}" (${doc.pageCount} S.)
Zitierbare Stellen: ${doc.citablePassages.slice(0, 3).map(p => `S. ${p.page}`).join(', ')}
Hauptargument: "${doc.citablePassages[0]?.text.substring(0, 120)}..."`).join('\n')}

## EMERGENTE MUSTER
${data.enhancedData.emergentPatterns.slice(0, 6).map(pattern => `- ${pattern}`).join('\n')}

## FORSCHUNGSERKENNTNISSE
${data.researchInsights.keyFindings.slice(0, 8).map(finding => `- ${finding}`).join('\n')}

${data.scientificRigority ? `## üî¨ WISSENSCHAFTLICHE RIGOROSIT√ÑT & REFLEXIVIT√ÑT
**Gesamt-Rigorosit√§ts-Score:** ${data.scientificRigority.scores.totalScore.toFixed(1)}/100 (${data.scientificRigority.scores.grade})
**Bewertung:** ${data.scientificRigority.summary.overallRigorityLevel}

### Rigorosit√§ts-Dimensionen
- Reflexive Authentizit√§t: ${(data.scientificRigority.scores.reflexiveAuthenticity * 100).toFixed(0)}%
- Methodologische Koh√§renz: ${(data.scientificRigority.scores.methodologicalCoherence * 100).toFixed(0)}%
- Theoretische S√§ttigung: ${(data.scientificRigority.scores.theoreticalSaturation * 100).toFixed(0)}%
- Hermeneutische Tiefe: ${(data.scientificRigority.scores.hermeneuticDepth * 100).toFixed(0)}%

### Forschungsreflexivit√§t
- **Analytische Memos:** ${data.scientificRigority.summary.totalMemos}
- **Forschungsnotizen:** ${data.scientificRigority.summary.totalNotes}
- **Reflexivit√§tseintr√§ge:** ${data.scientificRigority.summary.totalReflexivityEntries}

${data.scientificRigority.memos.length > 0 ? `### Ausgew√§hlte Memos f√ºr Berichtintegration
${data.scientificRigority.memos.slice(0, 3).map((m, i) => `**Memo ${i+1} (${m.type}):** ${m.content.substring(0, 200)}...`).join('\n')}` : ''}

${data.scientificRigority.summary.strengths.length > 0 ? `### Methodologische St√§rken
${data.scientificRigority.summary.strengths.map(s => `- ${s}`).join('\n')}` : ''}
` : ''}

**WICHTIG:** Verwende MINDESTENS 15-20 Literaturverweise aus den obigen Prim√§rquellen! Jede Hauptaussage muss mit konkreten Zitaten (Autor, Jahr, Seite) belegt werden. Integriere die wissenschaftliche Reflexivit√§t in den Methodenteil!`;
  }

  /**
   * Create comprehensive data context for AI (LEGACY - keeping for reference)
   */
  private static createDataContext(data: UltimateAnalysisData): string {
    return `
## PROJEKT√úBERSICHT
- **Forschungsbereich:** ${data.projectOverview.researchDomain}
- **Titel:** ${data.projectOverview.name}
- **Umfang:** ${data.projectOverview.totalDocuments} Dokumente, ${data.projectOverview.totalWords.toLocaleString()} W√∂rter
- **Analytische Tiefe:** ${data.projectOverview.totalCodings} Codierungen in ${data.projectOverview.totalCategories} Kategorien

## DOKUMENTENANALYSE (BASIS)
${data.basisData.documentSummaries.map(doc => `
### "${doc.name}"
- **W√∂rter:** ${doc.wordCount.toLocaleString()}
- **Schl√ºsselthemen:** ${doc.keyTopics.join(', ')}
- **Methodik:** ${doc.methodology}
- **Zentrale Erkenntnisse:** ${doc.findings}
- **Repr√§sentative Zitate:**
${doc.extractedQuotes.map(quote => `  - "${quote}"`).join('\n')}
`).join('\n')}

## KATEGORIENANALYSE (ENHANCED)
${data.enhancedData.categoryAnalysis.map(cat => `
### Kategorie: ${cat.name}
- **Codierungen:** ${cat.codingCount}
- **Signifikanz:** ${cat.significance}
- **Verbindungsst√§rke:** ${cat.connectionStrength}
- **Repr√§sentative Aussagen:**
${cat.representativeQuotes.slice(0, 3).map(quote => `  - "${quote}"`).join('\n')}
`).join('\n')}

## EMERGENTE MUSTER
${data.enhancedData.emergentPatterns.map(pattern => `- ${pattern}`).join('\n')}

## KATEGORIE-VERBINDUNGEN
${data.enhancedData.crossCategoryConnections.map(conn => `- ${conn}`).join('\n')}

## LITERATUR & ZITATIONEN
${data.literatureMapping.documents.map(doc => `
### Quelle: ${doc.extractedAuthor} (${doc.year}): "${doc.name}"
- **Seitenzahl:** ca. ${doc.pageCount} Seiten
- **Zitierbare Passagen:**
${doc.citablePassages.slice(0, 5).map(passage =>
  `  - S. ${passage.page}: "${passage.text.substring(0, 150)}..." [Kategorie: ${passage.category}]`
).join('\n')}
`).join('\n')}

## FORSCHUNGSERKENNTNISSE
### Zentrale Befunde:
${data.researchInsights.keyFindings.slice(0, 8).map(finding => `- "${finding.substring(0, 200)}..."`).join('\n')}

### Theoretische Beitr√§ge:
${data.researchInsights.theoreticalContributions.slice(0, 5).map(contrib => `- ${contrib}`).join('\n')}

### Praktische Implikationen:
${data.researchInsights.practicalImplications.slice(0, 5).map(impl => `- ${impl}`).join('\n')}

## QUALIT√ÑTSMETRIKEN
- **Pr√§zision:** ${(data.enhancedData.qualityMetrics.precision * 100).toFixed(1)}%
- **Recall:** ${(data.enhancedData.qualityMetrics.recall * 100).toFixed(1)}%
- **F1-Score:** ${(data.enhancedData.qualityMetrics.f1Score * 100).toFixed(1)}%
- **AKIH-Score:** ${data.enhancedData.akihScore.total?.toFixed(2)} (${data.enhancedData.akihScore.grade})
`;
  }

  // Helper methods
  private static determineResearchDomain(projectName: string, documents: DocumentData[]): string {
    const name = projectName.toLowerCase();
    if (name.includes('education') || name.includes('bildung')) return 'Bildungswissenschaften';
    if (name.includes('health') || name.includes('gesundheit')) return 'Gesundheitswissenschaften';
    if (name.includes('business') || name.includes('management')) return 'Wirtschaftswissenschaften';
    if (name.includes('psychology') || name.includes('psychologie')) return 'Psychologie';
    if (name.includes('technology') || name.includes('technologie')) return 'Technologie';
    return 'Interdisziplin√§re Forschung';
  }

  private static extractKeyTopics(content: string): string[] {
    if (!content) return [];
    const words = content.toLowerCase().match(/\b\w{4,}\b/g) || [];
    const frequency: {[key: string]: number} = {};
    words.forEach(word => frequency[word] = (frequency[word] || 0) + 1);
    return Object.entries(frequency)
      .sort(([,a], [,b]) => b - a)
      .slice(0, 8)
      .map(([word]) => word);
  }

  private static extractMethodology(content: string): string {
    if (!content) return 'Nicht spezifiziert';
    const methodKeywords = ['methode', 'approach', 'framework', 'analyse', 'studie', 'verfahren', 'untersuchung'];
    const sentences = content.split('.').filter(s =>
      methodKeywords.some(keyword => s.toLowerCase().includes(keyword))
    );
    return sentences[0]?.substring(0, 300) || 'Methodik aus Dokumentinhalt ableitbar';
  }

  private static extractFindings(content: string): string {
    if (!content) return 'Keine Erkenntnisse verf√ºgbar';
    const findingKeywords = ['ergebnis', 'finding', 'result', 'conclusion', 'shows', 'ergab', 'zeigt', 'deutet'];
    const sentences = content.split('.').filter(s =>
      findingKeywords.some(keyword => s.toLowerCase().includes(keyword))
    );
    return sentences.slice(0, 3).join('. ') || 'Erkenntnisse aus Dokumentanalyse';
  }

  private static extractSignificantQuotes(content: string, codings: CodingData[]): string[] {
    // Extract quotes that are also in codings (high significance)
    const relevantCodings = codings.filter(coding =>
      content.toLowerCase().includes(coding.text.toLowerCase().substring(0, 50))
    );
    return relevantCodings.slice(0, 5).map(coding => coding.text);
  }

  private static calculateCategoryDistribution(codings: CodingData[]): { [category: string]: number } {
    const distribution: { [category: string]: number } = {};
    codings.forEach(coding => {
      distribution[coding.category] = (distribution[coding.category] || 0) + 1;
    });
    return distribution;
  }

  private static calculateCategorySignificance(codings: CodingData[], categoryName: string): string {
    const categoryCodings = codings.filter(c => c.category === categoryName);
    const ratio = categoryCodings.length / codings.length;
    if (ratio > 0.3) return 'Hoch';
    if (ratio > 0.15) return 'Mittel';
    return 'Niedrig';
  }

  private static calculateConnectionStrength(categoryName: string, codings: CodingData[]): number {
    const categoryCodings = codings.filter(c => c.category === categoryName);
    const avgLength = categoryCodings.reduce((sum, c) => sum + c.text.length, 0) / categoryCodings.length;
    return Math.min(avgLength / 100, 1); // Normalize to 0-1
  }

  private static identifyEmergentPatterns(codings: CodingData[]): string[] {
    const textFreq: {[key: string]: number} = {};
    codings.forEach(coding => {
      const words = coding.text.toLowerCase().match(/\b\w{4,}\b/g) || [];
      words.forEach(word => textFreq[word] = (textFreq[word] || 0) + 1);
    });
    return Object.entries(textFreq)
      .sort(([,a], [,b]) => b - a)
      .slice(0, 12)
      .map(([pattern]) => pattern);
  }

  private static findCrossCategoryConnections(codings: CodingData[], categories: CategoryData[]): string[] {
    const connections: string[] = [];
    categories.forEach(cat1 => {
      categories.forEach(cat2 => {
        if (cat1.name !== cat2.name) {
          const overlap = codings.filter(c =>
            c.category === cat1.name &&
            codings.some(other => other.category === cat2.name &&
              other.text.toLowerCase().includes(c.text.toLowerCase().split(' ')[0]))
          );
          if (overlap.length > 0) {
            connections.push(`${cat1.name} ‚Üî ${cat2.name} (${overlap.length} Verbindungen)`);
          }
        }
      });
    });
    return connections.slice(0, 8);
  }

  private static extractAuthorInfo(content: string, fallbackIndex: number): { author: string; year: number } {
    // Advanced author extraction patterns
    const authorPatterns = [
      /(?:von|by|autor|author|written\s+by)[:\s]*([A-Z][a-zA-Z\s,&.]{5,50})/gi,
      /([A-Z][a-z]+,?\s+[A-Z][a-z]*\.?(?:\s+[A-Z][a-z]+)*)\s*\((\d{4})\)/g,
      /([A-Z][a-z]+\s+(?:et\s+al\.?|&\s+[A-Z][a-z]+))\s*\((\d{4})\)/g,
      /^([A-Z][a-z]+(?:\s+[A-Z][a-z]+){1,3})/m,
      /Verfasser[:\s]*([A-Z][a-zA-Z\s,&.]{5,50})/gi
    ];

    let extractedAuthor = `Autor${fallbackIndex + 1}`;
    let year = new Date().getFullYear();

    for (const pattern of authorPatterns) {
      const matches = content.match(pattern);
      if (matches && matches[0]) {
        let authorMatch = matches[0];
        authorMatch = authorMatch.replace(/^(von|by|autor|author|written\s+by|verfasser)[:\s]*/gi, '');
        const yearMatch = authorMatch.match(/\((\d{4})\)/);

        if (yearMatch) {
          year = parseInt(yearMatch[1]);
          authorMatch = authorMatch.replace(/\(\d{4}\)/, '').trim();
        }

        if (authorMatch.length > 2 && authorMatch.length < 80) {
          extractedAuthor = authorMatch.trim();
          break;
        }
      }
    }

    return { author: extractedAuthor, year };
  }

  private static extractCitablePassages(doc: DocumentData, codings: CodingData[]): CitablePassage[] {
    const documentCodings = codings.filter(c => c.text.length > 50); // Only substantial codings
    const passages: CitablePassage[] = [];

    documentCodings.slice(0, 10).forEach((coding, index) => {
      const page = Math.ceil((index + 1) * doc.wordCount / documentCodings.length / 250) + 1;
      passages.push({
        text: coding.text,
        page: page,
        context: `Kategorie: ${coding.category}`,
        category: coding.category
      });
    });

    return passages;
  }

  private static extractPracticalImplications(content: string): string[] {
    const implicationKeywords = ['anwendung', 'praxis', 'implementation', 'umsetzung', 'empfehlung', 'application'];
    const sentences = content.split('.').filter(s =>
      implicationKeywords.some(keyword => s.toLowerCase().includes(keyword)) && s.length > 50
    );
    return sentences.slice(0, 3);
  }
}